{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ler todos os arquivos csv do diretório e guardar em um objeto\n",
    "import os\n",
    "all_files = list(filter(lambda x: '.csv' in x, os.listdir('sakila_data/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar a leitura para cada arquivo \n",
    "import pandas as pd\n",
    "\n",
    "full_dataset = []\n",
    "\n",
    "for elem in all_files:\n",
    "    data = pd.read_csv('sakila_data/'+ elem)\n",
    "    full_dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "# estabelecendo a conexão e criando o banco\n",
    "con = sqlite3.connect('py_database_films.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma lista com os nomes das tabelas\n",
    "table_names = all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo os campos de todas as tabelas\n",
    "table_fields = []\n",
    "for i in  range(0, len(table_names)):\n",
    "    columnNames = list(full_dataset[i].head(0))\n",
    "    table_fields.append(columnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando as tabelas no SQLite\n",
    "for item in range(0,len(table_names)):\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS \"\"\" + table_names[item] + \"\"\"(\"\"\" + ','.join(table_fields[item])+\"\"\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varre todas as tabelas do nosso interese e para cada uma é realizado a inserção dos dados\n",
    "for ind in range(0, len(table_names)):\n",
    "\n",
    "    query = \"\"\"INSERT INTO \"\"\" + str(table_names[ind])  + \"\"\"(\"\"\" + ','.join(table_fields[ind]) + \"\"\") VALUES (\"\"\"+ ','.join(map(str,'?'*len(full_dataset[ind].columns))) +\"\"\")\"\"\"\n",
    "\n",
    "    full_dataset[ind] = full_dataset[ind].astype(str)\n",
    "\n",
    "    for i in range(0, len(full_dataset[ind])):\n",
    "        insert_register = tuple(full_dataset[ind].iloc[i])\n",
    "        cur.execute(query, insert_register)\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
